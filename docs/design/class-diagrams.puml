@startuml Mimasa - Components Class Diagrams

class User {
    +openApp()
    +grantPermission()
    +uploadVideo(video: Video)
    +selectLanguage(language: String)
    +submitRequest(language: String, video: Video)
    +receiveNotification(notification: String)
    +displayTranslation(translation: Translation)
    +saveTranslation(translation: Translation)
    +shareTranslation(translation: Translation)
}

class MediaProcessor {
    +videoProcessor: VideoProcessor
    +audiProcessor: AudiProcessor
    +audioAndVideoSyncer: AudioAndVideoSyncer
}

class MimasaApp {
    +mediaAccess: MediaAccess
    +mediaProcessor: MediaProcessor
    +showTranslation(translation: Translation)
    +notifyUser()
}

class VideoProcessor {
    +extractAudioFromVideo(): Audio
    +emoteTrans: EmoteTrans
    +createTranslation(video: Video)
    +getTranslation(): Video
}

class AudiProcessor {
    +translate(audio: Audio)
    +preprocessor: AudioPreprocessor
    +audioSeparator: AudioSeparator
    +speechTranslator: SpeechTranslator
    +postprocessor: AudioPostprocessor
    +getTranslation(): Audio
}

class AudioAndVideoSyncer {
    +sync(video: Video, audio: Audio): Video
}

class Translation {
    +video: Video
    +audio: Audio
}

class VideoOutput {
    +display(video: Video)
    +save(video: Video)
    +share(video: Video, platform: String)
}

class MediaAccess {
    +requestAccess()
}

class Video {
    +file: String
    +language: String
}

class Audio {
    +file: String
    +language: String
}

class FacialFeatures {
    +emotions: List<Emotions>
}

class ImagePreprocessor {
    +extractFacialFeatures(video: Video)
    +facialFeatures: FacialFeatures
}

class LipMovementSynchronizer {
    +syncLipMovements(video: Video, audio: Audio)
}

class FaceMovementSynchronizer {
    +syncFaceMovements(video: Video, audio: Audio)
}

class MovementSynchronizer {
    +lipMovementSynchronizer: LipMovementSynchronizer
    +faceMovementSynchronizer: FaceMovementSynchronizer
}

class EmoteTrans {
    +preprocessVideo(video: Video)
    +imagePreprocessor: ImagePreprocessor
    +identifyEmotions(features: FacialFeatures)
    +waitForTranslation(translation: Translation)
    +movementSynchronizer: MovementSynchronizer
}

class AudioPreprocessor {
    +postprocessAudio(audio: Audio)
}

class AudioSeparator {
    +separateVocalsAndMusic(audio: Audio)
    +getVocals(): Audio
    +getMusic(): Audio
}

class SpeechToTextTranslator {
    -translate(audio: Audio)
    +getTranslatedText(): string
}

class TextToSpeechTranslator {
    -translate(text: string)
    +getTranslatedAudio(): Audio
}

class SpeechTranslator {
    +speechToTextTranslator: SpeechToTextTranslator
    +textToSpeechTranslator: TextToSpeechTranslator
}

class AudioPostprocessor {
    -determineVocalsPosition(audio: Audio)
    -overlayAudioWithMusic(speech: Audio, music: Audio)
    +postprocessAudio(vocals: Audio, music: Audio)
}

User -down-> MimasaApp

MimasaApp -down-> MediaAccess
MimasaApp -down-> MediaProcessor

MediaProcessor -down-> VideoProcessor
MediaProcessor -down-> AudiProcessor
MediaProcessor -down-> AudioAndVideoSyncer

'video processing components'
VideoProcessor -down-> EmoteTrans
VideoProcessor -down-> Video

EmoteTrans -down-> ImagePreprocessor
EmoteTrans -down-> FacialFeatures
EmoteTrans -down-> MovementSynchronizer

MovementSynchronizer -down-> LipMovementSynchronizer
MovementSynchronizer -down-> FaceMovementSynchronizer

'audio processing components'
AudiProcessor -down-> AudioPreprocessor
AudiProcessor -down-> AudioSeparator
AudiProcessor -down-> SpeechTranslator
AudiProcessor -down-> AudioPostprocessor
AudioProcessor -down-> Audio

SpeechTranslator -down-> SpeechToTextTranslator
SpeechTranslator -down-> TextToSpeechTranslator

Translation -down-> Audio
Translation -down-> Video

MimasaApp -down-> VideoOutput

@enduml
